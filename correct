#!/usr/bin/env python

# Flush stdout
import sys
import os
import json
sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)

from pcgen import PathfinderCampaign
from pcgen.parser import describes_valid_lst_object, SpellObject
from pcgen.qa import QASpellSourceLink
from prd import get_prd_spell_links

print "# Pathfinder PRD SOURCELINK Cleanup Run"
print


###
# Configure objects
###

qa = QASpellSourceLink()
campaign = PathfinderCampaign()
lstfiles = campaign.find_spell_listfiles()

###
# Get PRD spells
###

with open("testdata/spells.html") as fh:
    html = fh.read()
    prdspells = get_prd_spell_links(html)


###
# Store fuzzer matches and misses
###

try:
    with open("suggestions") as fh:
        suggestions = json.loads(fh.read())
except IOError:
    suggestions = { "matcher": {}, "links": {} }
except ValueError as e:
    print
    print "COULD NOT PARSE SUGGESTIONS FILE!"
    print
    print e
    print
    sys.exit(1)

misses = []

###
# correct each file
###
for (lstfile, sourcedef) in lstfiles:
    print
    print "## Opening %s" % sourcedef["sourcelong"]
    print
    print lstfile
    print

    # read original data
    lstfh = open(lstfile)
    data = lstfh.read()
    lines = data.split("\n")
    lstfh.close()

    # write new data
    with open(lstfile, 'w') as writelstfh:
        for line in lines:

            if describes_valid_lst_object(line):
                spell = SpellObject(line, sourcedef)

                if qa.testlink(spell):  # test to see if correction is needed
                    print " - Fixing %s" % spell.name
                    result = qa.correct(spell, prdspells, suggestions=suggestions)

                    if result:
                        if result["method"] == "fuzzy":
                            print "   - fuzzy match [%s](%s)" % (result["match"], spell.sourcelink)
                            suggestions["matcher"][spell.name] = result["match"]
                    else:
                        print "   - cannot find a match in PRD index"
                        misses.append(spell.name)

                writelstfh.write(spell.lstline + "\n")

            else:
                writelstfh.write(line + "\n")

with open("suggestions.new", "w") as fh:
    fh.write(json.dumps(suggestions, sort_keys=True, indent=4, separators=(',', ': ')))

with open("misses", "w") as fh:
    fh.write("\n".join(misses))
